# -*- coding: utf-8 -*-
"""Quake_scrap.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pb-If1LEVv5v3-VBtZKoK40j0midJSY1
"""

import requests
from bs4 import BeautifulSoup
headers={'user-agent':'(Windows NT 6.1)Chrome/107.0.0.0'}
url='https://www.nature.com/articles/s41598-023-31627-3'
data=[]

response=requests.get(url, headers=headers)
soup=BeautifulSoup(response.content,'html.parser')
content=soup.find('div',class_='main-content').text
data.append(content)
data

pip install pyLDAvis

# Import necessary libraries
import gensim
from gensim import corpora
import pyLDAvis.gensim_models
import matplotlib.pyplot as plt
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Define a function for topic modeling
def topic_modeling(text, num_topics=5, num_words=10):
    # Tokenize the text
    text_tokens = gensim.utils.simple_preprocess(text, deacc=True, min_len=3)
    print(text_tokens)
    
    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [token for token in text_tokens if token not in stop_words]

    # Lemmatize words
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]

    # Create a dictionary from the tokenized text
    dictionary = corpora.Dictionary([lemmatized_tokens])
    
    # Create a bag of words from the dictionary
    bow_corpus = [dictionary.doc2bow(lemmatized_tokens)]
    
    # Train the LDA model
    lda_model = gensim.models.LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=10)
    
    # Print the top words for each topic
    for idx, topic in lda_model.print_topics(num_topics=num_topics, num_words=num_words):
        print("Topic: {} \nWords: {}".format(idx, topic))
    
    # Visualize the topics
    pyLDAvis.enable_notebook()
    vis = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary, R=30)
    return vis

# Perform topic modeling and visualization
topic_modeling(content)